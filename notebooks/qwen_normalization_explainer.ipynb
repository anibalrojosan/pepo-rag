{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0c7879fc",
      "metadata": {},
      "source": [
        "# Why Qwen Needed Output Normalization for RAG JSON Compliance\n",
        "\n",
        "This notebook documents why `ollama:qwen2.5:3b` required output normalization before its responses could be validated against our strict `RagResponse` schema.\n",
        "\n",
        "## Goals\n",
        "\n",
        "1. Show real output examples from the 5 golden questions.\n",
        "2. Explain why raw outputs do not match strict Pydantic validation.\n",
        "3. Describe the validation and normalization pipeline added for Qwen.\n",
        "4. Demonstrate how normalized outputs become schema-compliant and usable.\n",
        "\n",
        "## Context\n",
        "\n",
        "- Raw evaluation artifact: `docs/rag_eval_results_qwen_raw.json`\n",
        "- Canonical schema: `app/schemas/rag_response.py`\n",
        "- Evaluation script with normalization: `scripts/eval_rag_quality_raw_qwen.py`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c41a6dbf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['model', 'json_parse_rate', 'native_schema_valid_rate', 'normalized_schema_valid_rate', 'avg_latency_native', 'avg_latency_normalized', 'details'])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from pprint import pprint\n",
        "\n",
        "RESULTS_PATH = Path(\"../docs/rag_eval_results_qwen_raw.json\")\n",
        "\n",
        "def load_results(path: Path):\n",
        "    data = json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "    assert isinstance(data, list) and len(data) > 0, \"Unexpected result format\"\n",
        "    return data[0]\n",
        "\n",
        "report = load_results(RESULTS_PATH)\n",
        "report.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "004f7df3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'avg_latency_native': 0,\n",
            " 'avg_latency_normalized': 4.658951663970948,\n",
            " 'json_parse_rate': 100.0,\n",
            " 'model': 'ollama:qwen2.5:3b',\n",
            " 'native_schema_valid_rate': 0.0,\n",
            " 'normalized_schema_valid_rate': 100.0,\n",
            " 'num_questions': 5}\n"
          ]
        }
      ],
      "source": [
        "summary = {\n",
        "    \"model\": report[\"model\"],\n",
        "    \"json_parse_rate\": report[\"json_parse_rate\"],\n",
        "    \"native_schema_valid_rate\": report[\"native_schema_valid_rate\"],\n",
        "    \"normalized_schema_valid_rate\": report[\"normalized_schema_valid_rate\"],\n",
        "    \"avg_latency_native\": report[\"avg_latency_native\"],\n",
        "    \"avg_latency_normalized\": report[\"avg_latency_normalized\"],\n",
        "    \"num_questions\": len(report[\"details\"]),\n",
        "}\n",
        "\n",
        "pprint(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "764e55c0",
      "metadata": {},
      "source": [
        "## 1) Real Qwen Outputs for the Golden Questions\n",
        "\n",
        "The next cell prints a concise view of each question:\n",
        "\n",
        "- `question_id`\n",
        "- Native validation status\n",
        "- Raw parsed keys from Qwen (`parsed_json`)\n",
        "- A short preview of the raw output string\n",
        "\n",
        "This section is intentionally focused on *what Qwen actually returned*, before any schema adaptation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "99a9881e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- q1_synthesis ---\n",
            "native_schema_ok: False\n",
            "normalized_schema_ok: True\n",
            "parsed_json keys: ['answer']\n",
            "raw_output preview: {   \"answer\": \"Processes are unique entities that can execute different applications concurrently, they usually involve its own resources like memory space and file handles but share CPU scheduling. Threads, on the other\n",
            "\n",
            "--- q2_json_list ---\n",
            "native_schema_ok: False\n",
            "normalized_schema_ok: True\n",
            "parsed_json keys: ['answer']\n",
            "raw_output preview: {   \"answer\": \"Atomicity, Consistency, Isolation\" }\n",
            "\n",
            "--- q3_faithfulness ---\n",
            "native_schema_ok: False\n",
            "normalized_schema_ok: True\n",
            "parsed_json keys: ['output']\n",
            "raw_output preview: {   \"output\": \"The provided guide does not cover the configuration for AMD Radeon GPUs and has no information regarding such a setup. It specifically focuses on CUDA drivers for NVIDIA GPUs, particularly mentioning GTX 1\n",
            "\n",
            "--- q4_multihop ---\n",
            "native_schema_ok: False\n",
            "normalized_schema_ok: True\n",
            "parsed_json keys: ['output']\n",
            "raw_output preview: {   \"output\": {     \"model_chosen\": \"Model B\",     \"rationale\": \"Given the requirement for at least 8GB of RAM and a maximum constraint of 8GB, Model B is the optimal choice with its required 4GB of RAM. Despite having t\n",
            "\n",
            "--- q5_spanish_instruction ---\n",
            "native_schema_ok: False\n",
            "normalized_schema_ok: True\n",
            "parsed_json keys: ['answer', 'follow_up_questions']\n",
            "raw_output preview: {   \"answer\": \"Un deadlock en español se define como una situación en la computación concurrente donde dos o más procesos están cada uno esperando al otro para liberar un recurso, o más de dos procesos están esperando re\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for d in report[\"details\"]:\n",
        "    parsed = d.get(\"parsed_json\")\n",
        "    parsed_keys = list(parsed.keys()) if isinstance(parsed, dict) else type(parsed).__name__\n",
        "    raw_preview = (d.get(\"raw_output\") or \"\").replace(\"\\n\", \" \")[:220]\n",
        "\n",
        "    print(f\"--- {d['question_id']} ---\")\n",
        "    print(\"native_schema_ok:\", d.get(\"native_schema_ok\"))\n",
        "    print(\"normalized_schema_ok:\", d.get(\"normalized_schema_ok\"))\n",
        "    print(\"parsed_json keys:\", parsed_keys)\n",
        "    print(\"raw_output preview:\", raw_preview)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "696fda6e",
      "metadata": {},
      "source": [
        "## 2) Why Raw Qwen Outputs Fail Strict Pydantic Validation\n",
        "\n",
        "Our canonical schema (`RagResponse`) requires these core fields:\n",
        "\n",
        "- `answer` (required)\n",
        "- `confidence_score` (required, float in `[0, 1]`)\n",
        "- `sources_used` (required, bool)\n",
        "\n",
        "`key_terms` and `reasoning` are more permissive, but the three required fields above must always exist.\n",
        "\n",
        "Qwen often returns semantically correct content in alternative shapes such as:\n",
        "\n",
        "- `{\"output\": \"...\"}`\n",
        "- `{\"output\": {\"model_chosen\": \"...\", \"rationale\": \"...\"}}`\n",
        "- `{\"response\": \"...\"}`\n",
        "\n",
        "Those structures are valid JSON, but they are not directly valid `RagResponse` payloads.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0376a747",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "q1_synthesis: missing native required fields -> ['confidence_score', 'sources_used']\n",
            "  native_schema_error: 2 validation errors for RagResponse\n",
            "\n",
            "q2_json_list: missing native required fields -> ['confidence_score', 'sources_used']\n",
            "  native_schema_error: 2 validation errors for RagResponse\n",
            "\n",
            "q3_faithfulness: missing native required fields -> ['answer', 'confidence_score', 'sources_used']\n",
            "  native_schema_error: 3 validation errors for RagResponse\n",
            "\n",
            "q4_multihop: missing native required fields -> ['answer', 'confidence_score', 'sources_used']\n",
            "  native_schema_error: 3 validation errors for RagResponse\n",
            "\n",
            "q5_spanish_instruction: missing native required fields -> ['confidence_score', 'sources_used']\n",
            "  native_schema_error: 2 validation errors for RagResponse\n",
            "\n"
          ]
        }
      ],
      "source": [
        "required_fields = [\"answer\", \"confidence_score\", \"sources_used\"]\n",
        "\n",
        "for d in report[\"details\"]:\n",
        "    parsed = d.get(\"parsed_json\") if isinstance(d.get(\"parsed_json\"), dict) else {}\n",
        "    missing = [f for f in required_fields if f not in parsed]\n",
        "\n",
        "    print(f\"{d['question_id']}: missing native required fields -> {missing}\")\n",
        "    if d.get(\"native_schema_error\"):\n",
        "        first_line = str(d[\"native_schema_error\"]).split(\"\\n\")[0]\n",
        "        print(\"  native_schema_error:\", first_line)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93f66bd3",
      "metadata": {},
      "source": [
        "## 3) New Qwen Validation + Normalization Pipeline\n",
        "\n",
        "The updated evaluator runs **three explicit gates** per question:\n",
        "\n",
        "1. **JSON parse gate**\n",
        "   - `json_ok`: verifies raw text can be parsed with `json.loads`.\n",
        "\n",
        "2. **Native schema gate**\n",
        "   - `native_schema_ok`: validates `parsed_json` directly with `RagResponse.model_validate(...)`.\n",
        "   - This measures strict, out-of-the-box compliance.\n",
        "\n",
        "3. **Normalized schema gate**\n",
        "   - `normalize_qwen_payload(parsed_json)` maps heterogeneous shapes into canonical keys.\n",
        "   - `normalized_schema_ok`: validates the normalized payload with `RagResponse.model_validate(...)`.\n",
        "\n",
        "Why this is necessary:\n",
        "\n",
        "- Qwen frequently returns JSON that is structurally different but semantically meaningful.\n",
        "- A deterministic adapter preserves useful content while enforcing one stable API contract for downstream components.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "db3f9369",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'json_ok': True,\n",
            "  'native_schema_ok': False,\n",
            "  'normalized_schema_ok': True,\n",
            "  'question_id': 'q1_synthesis'},\n",
            " {'json_ok': True,\n",
            "  'native_schema_ok': False,\n",
            "  'normalized_schema_ok': True,\n",
            "  'question_id': 'q2_json_list'},\n",
            " {'json_ok': True,\n",
            "  'native_schema_ok': False,\n",
            "  'normalized_schema_ok': True,\n",
            "  'question_id': 'q3_faithfulness'},\n",
            " {'json_ok': True,\n",
            "  'native_schema_ok': False,\n",
            "  'normalized_schema_ok': True,\n",
            "  'question_id': 'q4_multihop'},\n",
            " {'json_ok': True,\n",
            "  'native_schema_ok': False,\n",
            "  'normalized_schema_ok': True,\n",
            "  'question_id': 'q5_spanish_instruction'}]\n"
          ]
        }
      ],
      "source": [
        "rows = []\n",
        "for d in report[\"details\"]:\n",
        "    rows.append({\n",
        "        \"question_id\": d[\"question_id\"],\n",
        "        \"json_ok\": d[\"json_ok\"],\n",
        "        \"native_schema_ok\": d[\"native_schema_ok\"],\n",
        "        \"normalized_schema_ok\": d[\"normalized_schema_ok\"],\n",
        "    })\n",
        "\n",
        "pprint(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d6d73fd",
      "metadata": {},
      "source": [
        "## 4) Before vs After Normalization (Per Question)\n",
        "\n",
        "The next cell prints one compact comparison per golden question:\n",
        "\n",
        "- **Raw shape** (`parsed_json` keys)\n",
        "- **Raw answer candidate** (if obvious)\n",
        "- **Normalized final answer** (`normalized_json[\"answer\"]`)\n",
        "- **Final canonical payload** (the `response` field stored by the evaluator)\n",
        "\n",
        "This is the practical evidence that normalization converts non-canonical but useful outputs into valid `RagResponse` objects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ec8f07a6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== q1_synthesis ===\n",
            "raw keys: ['answer']\n",
            "raw answer hint: Processes are unique entities that can execute different applications concurrently, they usually involve its own resources like memory space and file handles but share CPU scheduling. Threads, on the  ...\n",
            "normalized answer: Processes are unique entities that can execute different applications concurrently, they usually involve its own resources like memory space and file handles but share CPU scheduling. Threads, on the other hand, are smaller units of work than processes; however, unlike processes, a single thread belongs to a process sharing resources such as memory and files. Furthermore, context switching among threads consumes less time compared to switching between independent threads or processes.\n",
            "canonical response object:\n",
            "{'answer': 'Processes are unique entities that can execute different '\n",
            "           'applications concurrently, they usually involve its own resources '\n",
            "           'like memory space and file handles but share CPU scheduling. '\n",
            "           'Threads, on the other hand, are smaller units of work than '\n",
            "           'processes; however, unlike processes, a single thread belongs to a '\n",
            "           'process sharing resources such as memory and files. Furthermore, '\n",
            "           'context switching among threads consumes less time compared to '\n",
            "           'switching between independent threads or processes.',\n",
            " 'confidence_score': 0.5,\n",
            " 'key_terms': [],\n",
            " 'reasoning': None,\n",
            " 'sources_used': True}\n",
            "\n",
            "=== q2_json_list ===\n",
            "raw keys: ['answer']\n",
            "raw answer hint: Atomicity, Consistency, Isolation \n",
            "normalized answer: Atomicity, Consistency, Isolation\n",
            "canonical response object:\n",
            "{'answer': 'Atomicity, Consistency, Isolation',\n",
            " 'confidence_score': 0.5,\n",
            " 'key_terms': [],\n",
            " 'reasoning': None,\n",
            " 'sources_used': True}\n",
            "\n",
            "=== q3_faithfulness ===\n",
            "raw keys: ['output']\n",
            "raw answer hint: The provided guide does not cover the configuration for AMD Radeon GPUs and has no information regarding such a setup. It specifically focuses on CUDA drivers for NVIDIA GPUs, particularly mentioning  ...\n",
            "normalized answer: The provided guide does not cover the configuration for AMD Radeon GPUs and has no information regarding such a setup. It specifically focuses on CUDA drivers for NVIDIA GPUs, particularly mentioning GTX 10 series, RTX 20 series, and RTX 30 series. There is no mention of AMD or any other GPU manufacturers, hence, it cannot be used for configuring an AMD Radeon GPU.\n",
            "canonical response object:\n",
            "{'answer': 'The provided guide does not cover the configuration for AMD Radeon '\n",
            "           'GPUs and has no information regarding such a setup. It '\n",
            "           'specifically focuses on CUDA drivers for NVIDIA GPUs, particularly '\n",
            "           'mentioning GTX 10 series, RTX 20 series, and RTX 30 series. There '\n",
            "           'is no mention of AMD or any other GPU manufacturers, hence, it '\n",
            "           'cannot be used for configuring an AMD Radeon GPU.',\n",
            " 'confidence_score': 0.5,\n",
            " 'key_terms': [],\n",
            " 'reasoning': None,\n",
            " 'sources_used': True}\n",
            "\n",
            "=== q4_multihop ===\n",
            "raw keys: ['output']\n",
            "raw answer hint: Given the requirement for at least 8GB of RAM and a maximum constraint of 8GB, Model B is the optimal choice with its required 4GB of RAM. Despite having twice the latency (200 ms) as compared to Mode ...\n",
            "normalized answer: Model chosen: Model B. Given the requirement for at least 8GB of RAM and a maximum constraint of 8GB, Model B is the optimal choice with its required 4GB of RAM. Despite having twice the latency (200 ms) as compared to Model A's 100 ms, this higher latency could be acceptable if it allows meeting the specified memory limit.\n",
            "canonical response object:\n",
            "{'answer': 'Model chosen: Model B. Given the requirement for at least 8GB of '\n",
            "           'RAM and a maximum constraint of 8GB, Model B is the optimal choice '\n",
            "           'with its required 4GB of RAM. Despite having twice the latency '\n",
            "           \"(200 ms) as compared to Model A's 100 ms, this higher latency \"\n",
            "           'could be acceptable if it allows meeting the specified memory '\n",
            "           'limit.',\n",
            " 'confidence_score': 0.5,\n",
            " 'key_terms': [],\n",
            " 'reasoning': None,\n",
            " 'sources_used': True}\n",
            "\n",
            "=== q5_spanish_instruction ===\n",
            "raw keys: ['answer', 'follow_up_questions']\n",
            "raw answer hint: Un deadlock en español se define como una situación en la computación concurrente donde dos o más procesos están cada uno esperando al otro para liberar un recurso, o más de dos procesos están esperan ...\n",
            "normalized answer: Un deadlock en español se define como una situación en la computación concurrente donde dos o más procesos están cada uno esperando al otro para liberar un recurso, o más de dos procesos están esperando recursos en cadena circular.\n",
            "canonical response object:\n",
            "{'answer': 'Un deadlock en español se define como una situación en la '\n",
            "           'computación concurrente donde dos o más procesos están cada uno '\n",
            "           'esperando al otro para liberar un recurso, o más de dos procesos '\n",
            "           'están esperando recursos en cadena circular.',\n",
            " 'confidence_score': 0.5,\n",
            " 'key_terms': [],\n",
            " 'reasoning': None,\n",
            " 'sources_used': True}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def raw_answer_hint(parsed):\n",
        "    if not isinstance(parsed, dict):\n",
        "        return None\n",
        "    if isinstance(parsed.get(\"answer\"), str):\n",
        "        return parsed[\"answer\"]\n",
        "    if isinstance(parsed.get(\"output\"), str):\n",
        "        return parsed[\"output\"]\n",
        "    if isinstance(parsed.get(\"response\"), str):\n",
        "        return parsed[\"response\"]\n",
        "    if isinstance(parsed.get(\"output\"), dict):\n",
        "        out = parsed[\"output\"]\n",
        "        if isinstance(out.get(\"value\"), str):\n",
        "            return out[\"value\"]\n",
        "        if isinstance(out.get(\"rationale\"), str):\n",
        "            return out[\"rationale\"]\n",
        "    return None\n",
        "\n",
        "for d in report[\"details\"]:\n",
        "    parsed = d.get(\"parsed_json\")\n",
        "    normalized = d.get(\"normalized_json\") or {}\n",
        "\n",
        "    print(f\"=== {d['question_id']} ===\")\n",
        "    print(\"raw keys:\", list(parsed.keys()) if isinstance(parsed, dict) else type(parsed).__name__)\n",
        "\n",
        "    hint = raw_answer_hint(parsed)\n",
        "    if isinstance(hint, str):\n",
        "        print(\"raw answer hint:\", hint[:200], \"...\" if len(hint) > 200 else \"\")\n",
        "    else:\n",
        "        print(\"raw answer hint: <not directly accessible from a single field>\")\n",
        "\n",
        "    print(\"normalized answer:\", normalized.get(\"answer\", \"<missing>\"))\n",
        "    print(\"canonical response object:\")\n",
        "    pprint(d.get(\"response\"))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3683e5d",
      "metadata": {},
      "source": [
        "## Final Interpretation\n",
        "\n",
        "During the evaluation of `Qwen2.5:3b`, it was concluded:\n",
        "\n",
        "- Qwen is highly reliable at producing **parseable JSON** (`json_parse_rate = 100%`).\n",
        "- Qwen does **not** natively satisfy strict `RagResponse` requirements (`native_schema_valid_rate = 0%`).\n",
        "- After deterministic normalization, outputs become fully compatible with the canonical schema (`normalized_schema_valid_rate = 100%`).\n",
        "\n",
        "This justifies keeping:\n",
        "\n",
        "- a single canonical API schema (`RagResponse`), and\n",
        "- a model-specific normalization layer for Qwen.\n",
        "\n",
        "This preserves contract stability for downstream systems while still leveraging useful outputs from other models.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
